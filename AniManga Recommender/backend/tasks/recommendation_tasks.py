"""
Recommendation Background Tasks for AniManga Recommender

This module contains Celery tasks for background processing of personalized
recommendations including:
- Individual user recommendation pre-computation
- Batch processing for multiple users
- Cache warming and management
- Performance monitoring and error handling

Tasks are designed to work with the existing recommendation system in app.py
and integrate seamlessly with the Redis caching infrastructure.
"""

import os
import sys
import traceback
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from celery import Task
from celery.exceptions import Retry, MaxRetriesExceededError

# Add parent directory to path to import app modules
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Import Celery app
from celery_app import celery_app

# Task execution metrics tracking
task_metrics = {
    'executions': 0,
    'successes': 0,
    'failures': 0,
    'total_time': 0.0,
    'last_execution': None
}

class RecommendationTask(Task):
    """
    Base task class for recommendation tasks with enhanced error handling.
    
    Provides common functionality for retry logic, error logging, and
    performance metrics tracking across all recommendation tasks.
    """
    
    autoretry_for = (Exception,)
    retry_kwargs = {'max_retries': 3, 'countdown': 60}
    retry_backoff = True
    retry_jitter = True
    
    def on_success(self, retval, task_id, args, kwargs):
        """Track successful task execution metrics"""
        task_metrics['successes'] += 1
        task_metrics['last_execution'] = datetime.now().isoformat()
        print(f"‚úÖ Task {self.name} completed successfully: {task_id}")
    
    def on_failure(self, exc, task_id, args, kwargs, einfo):
        """Track failed task execution and log errors"""
        task_metrics['failures'] += 1
        print(f"‚ùå Task {self.name} failed: {task_id}")
        print(f"Error: {exc}")
        print(f"Traceback: {einfo}")
    
    def on_retry(self, exc, task_id, args, kwargs, einfo):
        """Log retry attempts"""
        print(f"üîÑ Retrying task {self.name}: {task_id} due to {exc}")

@celery_app.task(bind=True, base=RecommendationTask, name='tasks.recommendation_tasks.precompute_user_recommendations')
def precompute_user_recommendations(self, user_id: str, force_refresh: bool = False) -> Dict[str, Any]:
    """
    Pre-compute personalized recommendations for a single user.
    
    This task generates fresh personalized recommendations and stores them
    in the cache, improving response times for subsequent API requests.
    Uses the existing recommendation generation logic from app.py.
    
    Args:
        user_id (str): UUID of the user to generate recommendations for
        force_refresh (bool): Force regeneration even if cache exists
        
    Returns:
        Dict[str, Any]: Task execution result with metrics and status
        
    Raises:
        Retry: If recommendation generation fails and retries are available
        MaxRetriesExceededError: If all retry attempts are exhausted
        
    Cache Strategy:
        - Checks existing cache first (unless force_refresh=True)
        - Generates fresh recommendations using existing algorithms
        - Stores results with 30-minute TTL
        - Tracks cache hit/miss rates for monitoring
        
    Performance:
        - Typical execution time: 2-5 seconds per user
        - Memory usage: ~50MB per concurrent task
        - Designed for batch processing efficiency
    """
    try:
        start_time = datetime.now()
        task_metrics['executions'] += 1
        
        print(f"ü§ñ Pre-computing recommendations for user: {user_id}")
        
        # Import app functions dynamically to avoid circular imports
        try:
            from app import (
                analyze_user_preferences,
                generate_personalized_recommendations,
                get_personalized_recommendation_cache,
                set_personalized_recommendation_cache
            )
        except ImportError as e:
            print(f"‚ùå Failed to import app functions: {e}")
            raise Exception(f"App module import failed: {e}")
        
        # Check if user has cached recommendations (unless forcing refresh)
        cached_data = None
        if not force_refresh:
            cached_data = get_personalized_recommendation_cache(user_id)
            if cached_data:
                execution_time = (datetime.now() - start_time).total_seconds()
                print(f"‚úÖ User {user_id} already has cached recommendations (skipped)")
                return {
                    'status': 'skipped_cached',
                    'user_id': user_id,
                    'execution_time': execution_time,
                    'cached': True,
                    'message': 'Recommendations already cached'
                }
        
        # Analyze user preferences
        try:
            user_preferences = analyze_user_preferences(user_id)
            if not user_preferences or user_preferences.get('total_items', 0) == 0:
                print(f"‚ö†Ô∏è User {user_id} has insufficient data for recommendations")
                return {
                    'status': 'skipped_insufficient_data',
                    'user_id': user_id,
                    'execution_time': (datetime.now() - start_time).total_seconds(),
                    'message': 'Insufficient user data for recommendations'
                }
        except Exception as e:
            print(f"‚ùå Failed to analyze user preferences for {user_id}: {e}")
            raise Exception(f"User preference analysis failed: {e}")
        
        # Generate personalized recommendations
        try:
            recommendations = generate_personalized_recommendations(
                user_id, user_preferences, limit=20
            )
            
            if not recommendations:
                raise Exception("Empty recommendations returned")
                
        except Exception as e:
            print(f"‚ùå Failed to generate recommendations for {user_id}: {e}")
            raise Exception(f"Recommendation generation failed: {e}")
        
        # Create user preferences summary
        try:
            user_prefs_summary = {
                'top_genres': list(sorted(user_preferences['genre_preferences'].items(), 
                                        key=lambda x: x[1], reverse=True)[:5]),
                'avg_rating': user_preferences['rating_patterns']['average_rating'],
                'preferred_length': _get_preferred_length_label(user_preferences['completion_tendencies']),
                'completion_rate': _calculate_completion_rate_from_prefs(user_preferences),
                'media_type_preference': user_preferences['media_type_preference']
            }
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to create user preferences summary: {e}")
            user_prefs_summary = {}
        
        # Prepare cache data
        cache_data = {
            'recommendations': recommendations,
            'user_preferences': user_prefs_summary,
            'cache_info': {
                'generated_at': datetime.now().isoformat(),
                'expires_at': (datetime.now() + timedelta(minutes=30)).isoformat(),
                'algorithm_version': '1.2',
                'cache_hit': False,
                'generated_by': 'background_task'
            }
        }
        
        # Store in cache
        try:
            cache_success = set_personalized_recommendation_cache(user_id, cache_data)
            if not cache_success:
                print(f"‚ö†Ô∏è Failed to cache recommendations for {user_id}")
        except Exception as e:
            print(f"‚ö†Ô∏è Cache storage failed for {user_id}: {e}")
            # Don't fail the task if caching fails
        
        execution_time = (datetime.now() - start_time).total_seconds()
        task_metrics['total_time'] += execution_time
        
        # Count recommendations generated
        total_recs = sum(len(recs) for recs in recommendations.values())
        
        print(f"‚úÖ Generated {total_recs} recommendations for user {user_id} in {execution_time:.2f}s")
        
        return {
            'status': 'success',
            'user_id': user_id,
            'execution_time': execution_time,
            'recommendations_count': total_recs,
            'cached': True,
            'sections': list(recommendations.keys()),
            'message': f'Successfully generated {total_recs} recommendations'
        }
        
    except Exception as exc:
        # Handle retries with exponential backoff
        if self.request.retries < self.max_retries:
            countdown = 60 * (2 ** self.request.retries)  # Exponential backoff
            print(f"üîÑ Retrying recommendation task for user {user_id} in {countdown}s")
            raise self.retry(exc=exc, countdown=countdown)
        else:
            print(f"‚ùå Max retries exceeded for user {user_id}: {exc}")
            return {
                'status': 'failed',
                'user_id': user_id,
                'error': str(exc),
                'message': f'Failed after {self.max_retries} retries'
            }

@celery_app.task(bind=True, base=RecommendationTask, name='tasks.recommendation_tasks.batch_precompute_recommendations')
def batch_precompute_recommendations(self, user_ids: List[str], force_refresh: bool = False) -> Dict[str, Any]:
    """
    Pre-compute recommendations for multiple users in a batch operation.
    
    Processes multiple users efficiently with proper error handling,
    progress tracking, and performance optimization. Designed for
    scheduled bulk processing of active users.
    
    Args:
        user_ids (List[str]): List of user UUIDs to process
        force_refresh (bool): Force regeneration for all users
        
    Returns:
        Dict[str, Any]: Batch processing results with detailed metrics
        
    Batch Processing Features:
        - Processes users sequentially to avoid resource contention
        - Tracks individual user success/failure rates
        - Provides detailed progress and performance metrics
        - Handles partial batch failures gracefully
        - Implements batch size optimization
        
    Performance Characteristics:
        - Optimal batch size: 10-20 users per task
        - Average processing time: 3-7 seconds per user
        - Memory usage scales linearly with batch size
        - Designed for off-peak hour execution
    """
    try:
        start_time = datetime.now()
        batch_size = len(user_ids)
        
        print(f"üîÑ Starting batch recommendation processing for {batch_size} users")
        
        # Initialize batch metrics
        batch_results = {
            'processed': 0,
            'successful': 0,
            'failed': 0,
            'skipped': 0,
            'total_time': 0.0,
            'user_results': [],
            'errors': []
        }
        
        # Process each user in the batch
        for i, user_id in enumerate(user_ids):
            try:
                print(f"ü§ñ Processing user {i+1}/{batch_size}: {user_id}")
                
                # Call individual user task function directly to avoid task overhead
                result = precompute_user_recommendations.apply(
                    args=[user_id, force_refresh],
                    throw=True  # Raise exceptions instead of returning failed results
                ).get()
                
                batch_results['processed'] += 1
                batch_results['user_results'].append(result)
                
                # Update status counters
                if result['status'] == 'success':
                    batch_results['successful'] += 1
                elif result['status'].startswith('skipped'):
                    batch_results['skipped'] += 1
                else:
                    batch_results['failed'] += 1
                    
                # Add execution time
                batch_results['total_time'] += result.get('execution_time', 0)
                
            except Exception as e:
                batch_results['processed'] += 1
                batch_results['failed'] += 1
                error_info = {
                    'user_id': user_id,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                }
                batch_results['errors'].append(error_info)
                batch_results['user_results'].append({
                    'status': 'failed',
                    'user_id': user_id,
                    'error': str(e)
                })
                print(f"‚ùå Failed to process user {user_id}: {e}")
                continue
        
        # Calculate final metrics
        total_execution_time = (datetime.now() - start_time).total_seconds()
        success_rate = (batch_results['successful'] / batch_size) * 100 if batch_size > 0 else 0
        avg_time_per_user = batch_results['total_time'] / batch_size if batch_size > 0 else 0
        
        print(f"‚úÖ Batch processing completed: {batch_results['successful']}/{batch_size} successful ({success_rate:.1f}%)")
        
        return {
            'status': 'completed',
            'batch_size': batch_size,
            'results': batch_results,
            'metrics': {
                'success_rate': success_rate,
                'total_execution_time': total_execution_time,
                'avg_time_per_user': avg_time_per_user,
                'processed_per_minute': (batch_size / total_execution_time) * 60 if total_execution_time > 0 else 0
            },
            'timestamp': datetime.now().isoformat(),
            'message': f'Processed {batch_size} users with {success_rate:.1f}% success rate'
        }
        
    except Exception as exc:
        print(f"‚ùå Batch processing failed: {exc}")
        traceback.print_exc()
        
        if self.request.retries < self.max_retries:
            countdown = 180 * (2 ** self.request.retries)  # Longer backoff for batch operations
            print(f"üîÑ Retrying batch processing in {countdown}s")
            raise self.retry(exc=exc, countdown=countdown)
        else:
            return {
                'status': 'failed',
                'batch_size': len(user_ids),
                'error': str(exc),
                'message': f'Batch processing failed after {self.max_retries} retries'
            }

@celery_app.task(bind=True, base=RecommendationTask, name='tasks.recommendation_tasks.warm_user_cache')
def warm_user_cache(self, user_id: str) -> Dict[str, Any]:
    """
    Warm the cache for a specific user by pre-generating recommendations.
    
    This is a lightweight version of precompute_user_recommendations that
    focuses specifically on cache warming operations, typically triggered
    by user activity events or scheduled warming cycles.
    
    Args:
        user_id (str): UUID of the user whose cache to warm
        
    Returns:
        Dict[str, Any]: Cache warming result with status and metrics
        
    Use Cases:
        - Pre-warm cache before user login
        - Refresh cache after user activity spikes
        - Maintain hot cache for frequent users
        - Emergency cache rebuilding operations
    """
    try:
        start_time = datetime.now()
        
        print(f"üî• Warming cache for user: {user_id}")
        
        # Use the existing precompute function but with cache warming semantics
        result = precompute_user_recommendations.apply(
            args=[user_id, False],  # Don't force refresh for warming
            throw=True
        ).get()
        
        execution_time = (datetime.now() - start_time).total_seconds()
        
        # Modify result for cache warming context
        result['operation'] = 'cache_warming'
        result['cache_warm_time'] = execution_time
        
        print(f"üî• Cache warming completed for user {user_id} in {execution_time:.2f}s")
        
        return result
        
    except Exception as exc:
        print(f"‚ùå Cache warming failed for user {user_id}: {exc}")
        
        if self.request.retries < self.max_retries:
            countdown = 30 * (2 ** self.request.retries)  # Faster retry for cache warming
            raise self.retry(exc=exc, countdown=countdown)
        else:
            return {
                'status': 'failed',
                'user_id': user_id,
                'operation': 'cache_warming',
                'error': str(exc),
                'message': 'Cache warming failed after retries'
            }

# Helper functions (need to be defined here to avoid import issues)
def _get_preferred_length_label(completion_tendencies: Dict[str, int]) -> str:
    """Convert completion tendencies to human-readable label"""
    if not completion_tendencies:
        return 'unknown'
    
    max_category = max(completion_tendencies.items(), key=lambda x: x[1])
    return max_category[0] if max_category[1] > 0 else 'unknown'

def _calculate_completion_rate_from_prefs(user_preferences: Dict[str, Any]) -> float:
    """Calculate completion rate from user preferences data"""
    try:
        # This is a simplified calculation - in production you'd have actual completion data
        total_items = user_preferences.get('total_items', 0)
        if total_items == 0:
            return 0.0
        
        # Estimate based on rating patterns (users who rate tend to complete more)
        rating_count = user_preferences.get('rating_patterns', {}).get('rating_count', 0)
        estimated_completion_rate = min(0.95, (rating_count / total_items) * 1.2)
        
        return round(estimated_completion_rate, 2)
    except Exception:
        return 0.0

def get_task_metrics() -> Dict[str, Any]:
    """
    Get current task execution metrics for monitoring.
    
    Returns:
        Dict[str, Any]: Task performance metrics and statistics
    """
    avg_time = task_metrics['total_time'] / task_metrics['executions'] if task_metrics['executions'] > 0 else 0
    success_rate = (task_metrics['successes'] / task_metrics['executions']) * 100 if task_metrics['executions'] > 0 else 0
    
    return {
        'total_executions': task_metrics['executions'],
        'successful_executions': task_metrics['successes'],
        'failed_executions': task_metrics['failures'],
        'success_rate_percent': round(success_rate, 2),
        'average_execution_time': round(avg_time, 2),
        'total_processing_time': round(task_metrics['total_time'], 2),
        'last_execution': task_metrics['last_execution']
    } 